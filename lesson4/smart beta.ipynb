{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tejdata = pd.read_csv('/smartbeta/smartbeta.csv')  \n",
    "tejdata['yyyy'] = np.round(tejdata['日期']/100)\n",
    "tejdata['coid'] = pd.DataFrame(tejdata['公司'].str.split(\" \").tolist(),columns=['A','B'])['A']\n",
    "tejdata['Momentum'] = tejdata['Momentum'].str.replace('%','').astype('float32')\n",
    "tejdata['持有一年報酬率'] = tejdata['持有一年報酬率'].str.replace('%','').astype('float32')\n",
    "tejdata['Momentum'] = tejdata['Momentum'] /100\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "yyyy_list = tejdata['yyyy'].unique().tolist()\n",
    "\n",
    "tejdata['總分'] = tejdata['總分'].fillna(0)\n",
    "tejdata['總分'] = tejdata['總分'] +10\n",
    "tejdata['Momentum'] = tejdata['Momentum'].fillna(0)\n",
    "\n",
    "#報酬率資料處理\n",
    "return_col_name = ['hold_Q1','hold_Q2','hold_Q3','hold_Q4','持有一年報酬率']\n",
    "for i in range(0,len(return_col_name)):\n",
    "    tejdata[return_col_name[i]] = tejdata[return_col_name[i]].fillna(0)\n",
    "    tejdata[return_col_name[i]]  = tejdata[return_col_name[i]] /100\n",
    "    tejdata.loc[tejdata[return_col_name[i]]>1,return_col_name[i]] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_col_name = ['淨值市價比','益本比(常續性利益)','現金股利率','現金流量模組指數','m_index','ROE(B)－常續利益']\n",
    "roi_col_name = ['持有一年報酬率','總分']\n",
    "\n",
    "n_max_steps = len(yyyy_list)\n",
    "n_inputs = len(train_col_name)\n",
    "sample_size = 500\n",
    "x_batch = np.zeros((n_max_steps,sample_size,1,n_inputs))\n",
    "y_batch = np.zeros((n_max_steps,sample_size,1))\n",
    "z_batch = np.zeros((n_max_steps,sample_size))\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "scaler = StandardScaler()\n",
    "for i in range(0,n_max_steps):\n",
    "    this_year = tejdata[tejdata['yyyy']==yyyy_list[i]].reset_index()\n",
    "    #計算動能分位數\n",
    "    this_year['m_n'] = pd.DataFrame(quantile_transform(tejdata.loc[tejdata['yyyy']==yyyy_list[i],'Momentum'].values.reshape(1,-1),n_quantiles=3, random_state=0,axis =1).T.tolist())\n",
    "    this_year['m_index'] = 1\n",
    "    this_year.loc[this_year['m_n']<0.6,'m_index'] = 0\n",
    "    this_year.loc[this_year['m_n']<0.3,'m_index'] = -1\n",
    "    #計算總分排序\n",
    "    this_year['total_score'] = 0\n",
    "    for j in range(0,len(train_col_name)):\n",
    "        this_year['total_score'] = this_year['total_score'] + this_year[train_col_name[j]]\n",
    "#    this_year['score_n'] = 500*this_year['score_n']\n",
    "    scaler.fit(this_year.reindex(columns=roi_col_name))\n",
    "    this_year['score_r'] = pd.DataFrame(scaler.transform(this_year.reindex(columns=roi_col_name)),columns=roi_col_name)['總分']\n",
    "\n",
    "    test_datas = this_year.reindex(columns=train_col_name).values\n",
    "    x_batch[i,:,0] = test_datas\n",
    "    roi = this_year.reindex(columns=['total_score']).values\n",
    "    y_batch[i,:,0] = roi[:,0]\n",
    "    roi = this_year.reindex(columns=['hold_Q1']).values\n",
    "    z_batch[i] = roi[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zyx\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf   \n",
    "\n",
    "tf.reset_default_graph()   \n",
    "sample_length = 30\n",
    "punishment = 5\n",
    "\n",
    "isTrain = False\n",
    "batch_size = 1\n",
    "learning_rate = 0.0005\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate) \n",
    "train_w_stddev = 0.3\n",
    "keep_prob =1.0\n",
    "# display_step = 10 #\n",
    "\n",
    "n_step = sample_length # h\n",
    "n_hidden = n_inputs\n",
    "n_classes = 1 #跟group一樣多\n",
    "num_layers = 3\n",
    "\n",
    "# placeholder\n",
    "x = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "actual_y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "#w_in  = tf.Variable(tf.truncated_normal([n_inputs, n_hidden], mean=0.0, stddev=train_w_stddev, dtype=tf.float32))\n",
    "w_out = tf.Variable(tf.truncated_normal([n_hidden, n_classes], mean=0.0, stddev=train_w_stddev, dtype=tf.float32))\n",
    "#b_in  = tf.Variable(tf.zeros(n_hidden, dtype = tf.float32))\n",
    "b_out = tf.Variable(tf.zeros(n_classes, dtype = tf.float32))\n",
    "\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer() \n",
    "\n",
    "#hidden  = tf.contrib.layers.fully_connected(tf.matmul(x     ,w_in )+b_in   ,n_hidden , activation_fn=tf.nn.relu,weights_initializer=initializer) \n",
    "logits  = tf.contrib.layers.fully_connected(tf.matmul(x,w_out)+b_out  ,n_classes, activation_fn=tf.nn.relu,weights_initializer=initializer) \n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=actual_y, logits=logits)\n",
    "cost = tf.reduce_mean(tf.square(logits -0.0))\n",
    "\n",
    "###增強式學習用\n",
    "grads_and_vars = optimizer.compute_gradients(cross_entropy) \n",
    "gradients = [variable for grad, variable in grads_and_vars] \n",
    "gradient_placeholders = [] \n",
    "grads_and_vars_feed = [] \n",
    "#計算平均梯度，避免梯度爆炸\n",
    "for grads, variable in grads_and_vars:\n",
    "#    X = tf.placeholder(tf.float32, shape=[None, n_inputs]) \n",
    "    gradient_placeholder = tf.placeholder(tf.float32, shape=variable.get_shape())\n",
    "    gradient_placeholders.append(gradient_placeholder)\n",
    "    grads_and_vars_feed.append((gradient_placeholder, variable)) \n",
    "training_op = optimizer.apply_gradients(grads_and_vars_feed) \n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "saver = tf.train.Saver() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n",
      "evaluating...\n",
      "0.0027432468804841625\n"
     ]
    }
   ],
   "source": [
    "punishment = 5\n",
    "#learning_rate = 0.001\n",
    "n_iterations = 1000000     # number of training iterations \n",
    "     # max steps per episode \n",
    "n_games_per_update = n_max_steps # train the policy every 10 episodes \n",
    "save_iterations = 10    # save the model every 10 training iterations \n",
    "discount_rate = 1\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6)\n",
    "samples = []\n",
    "ckpt_file = '/smartbeta/'\n",
    "confident_level_0 = 0.97\n",
    "confident_level_1 = 0.83\n",
    "correct_rate=0.5000\n",
    "break_rate=0.01909\n",
    "cost_val = 0\n",
    "choose_stock_num = 50\n",
    "#config=tf.ConfigProto(gpu_options=gpu_options,log_device_placement=True)\n",
    "with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(ckpt_file)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        print('restoring...')\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        print('not found')\n",
    "        init.run()   \n",
    "    if isTrain:\n",
    "        print(\"start training\")\n",
    "    else:\n",
    "        print(\"evaluating...\")\n",
    "        n_iterations = 1\n",
    "        keep_prob=1.0       \n",
    "    for iteration in range(n_iterations):\n",
    "        count_1 = 0\n",
    "        count_0 = 0                \n",
    "        all_actions = []\n",
    "        all_rewards = []    \n",
    "        all_gradients = []  \n",
    "        all_reward_test = []\n",
    "        for game in range(3,n_games_per_update):  \n",
    "            \n",
    "            current_predict = 0\n",
    "            current_rewards = 0\n",
    "#            current_gradients = [] \n",
    "            current_reward_test = []\n",
    "#                x_sample_index = np.random.randint(low=1,high=(allsample_length+1), size=1)[0]\n",
    "#            for step in range(0,1):\n",
    "\n",
    "            logits_val,cost_val,gradients_val = sess.run([logits,cost,gradients],feed_dict={actual_y:y_batch[game].reshape(-1,1),x: x_batch[game].reshape(-1,6)}) # one obs\n",
    "#                print(str(logits_val)+\" \"+str(y_batch[game][step]))\n",
    "            current_gradients = gradients_val            \n",
    "            current_predict = logits_val[:,0]\n",
    "            current_rewards = [1]*len(current_predict)\n",
    "            temp_current_predict = np.sort(current_predict.copy())\n",
    "            temp_current_predict = temp_current_predict[::-1]\n",
    "            buy_index_logits = temp_current_predict[choose_stock_num-1]\n",
    "            reward_count = 0\n",
    "            for i in range(0,len(current_predict)):\n",
    "                if current_predict[i]<buy_index_logits:\n",
    "                    current_rewards[i]=0\n",
    "                    current_reward_test.append(0)\n",
    "                else:\n",
    "#                    current_rewards[i]=1\n",
    "                    a = (1+z_batch[game-1][i])*(1+z_batch[game-2][i])*(1+z_batch[game-3][i]) -1\n",
    "                    current_rewards.append(a)\n",
    "#                    current_rewards[i]=1\n",
    "                    current_reward_test.append(z_batch[game][i])           \n",
    "                    reward_count+=1\n",
    "            mean_current_rewards = np.sum(current_rewards)/reward_count\n",
    "            mean_current_rewards_test = np.sum(current_reward_test)/reward_count\n",
    "            all_gradients.append(current_gradients)\n",
    "            all_rewards.append(mean_current_rewards)\n",
    "            all_reward_test.append(mean_current_rewards_test)\n",
    "#            all_rewards = discount_and_normalize_rewards(all_rewards,discount_rate)\n",
    "        feed_dict = {}\n",
    "        for var_index, grad_placeholder in enumerate(gradient_placeholders):\n",
    "            # 加工梯度\n",
    "            this_mean = []\n",
    "            for game_index, rewards in enumerate(all_rewards):\n",
    "#                for step, reward in enumerate(rewards):            \n",
    "                r_g = rewards * all_gradients[game_index][var_index]\n",
    "                this_mean.append(r_g)\n",
    "            mean_gradients = np.mean(this_mean,axis=0)\n",
    "#            mean_gradients = np.mean([reward * all_gradients[game_index][step][var_index]for game_index, rewards in enumerate(all_rewards)for step, reward in enumerate(rewards)],axis=0)\n",
    "            feed_dict[grad_placeholder] = mean_gradients        \n",
    "        avg_retrun = np.mean(all_reward_test)\n",
    "        if iteration%100==0:\n",
    "            print(np.mean(all_reward_test))\n",
    "        if avg_retrun>0.10:\n",
    "            saver.save(sess, ckpt_file+\"model_\"+str(round(avg_retrun,6))+\"_beta.ckpt\")  \n",
    "#            learning_rate = 0.0001\n",
    "#        else:\n",
    "#            learning_rate = 0.001\n",
    "        if isTrain:\n",
    "            apply = sess.run(training_op, feed_dict=feed_dict)          \n",
    "        else:            \n",
    "            w1,b1 = sess.run([w_out,b_out], feed_dict=feed_dict)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
